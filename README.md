<h1 align="center">NeuraHome AI Customer Support</h1>

<div align="center">

![Version](https://img.shields.io/badge/version-1.0.0-blue.svg)
![Python](https://img.shields.io/badge/python-3.8+-green.svg)
![Next.js](https://img.shields.io/badge/next.js-16.0.6-black.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

**An intelligent AI-powered customer support system with RAG (Retrieval-Augmented Generation) capabilities, powered by LangChain agents**

[Features](#-features) â€¢ [Quick Start](#-quick-start) â€¢ [Documentation](#-documentation) â€¢ [API Reference](#-api-reference)

</div>

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Screenshots](#-screenshots)
- [Features](#-features)
- [Tech Stack](#-tech-stack)
- [Architecture](#-architecture)
- [Prerequisites](#-prerequisites)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Running the Application](#-running-the-application)
- [API Reference](#-api-reference)
- [Project Structure](#-project-structure)
- [Environment Variables](#-environment-variables)
- [Testing](#-testing)
- [Deployment](#-deployment)
- [Contributing](#-contributing)
- [License](#-license)

---

## ğŸ¯ Overview

NeuraHome AI Customer Support is a comprehensive customer support system that leverages advanced AI technologies to provide intelligent, context-aware assistance. The system combines Retrieval-Augmented Generation (RAG) with LangChain agents to deliver accurate responses from product documentation, FAQs, and troubleshooting guides.

### Key Capabilities

- **Intelligent Query Routing**: Automatically determines whether to use RAG retrieval or direct LLM reasoning
- **Conversation Memory**: Maintains context across multiple interactions using Redis
- **Multi-Tool Support**: Integrates order lookup, ticket creation, and address management
- **Source Attribution**: Provides citations and source references for transparency
- **Modern Web Interface**: Beautiful, responsive Next.js frontend

---

## ğŸ“¸ Screenshots

<div align="center">

### Application Interface

![Screenshot 1](assest/1.png)

*Main chat interface with conversation history*

![Screenshot 2](assest/2.png)

*Interactive features and response display*

![Screenshot 3](assest/3.png)

*Source attribution and tool indicators*

</div>

---

## âœ¨ Features

### Core Features

- ğŸ¤– **Intelligent Agent System**: LangChain ReAct agent that intelligently routes queries
- ğŸ“š **RAG-Powered Knowledge Base**: Vector search over product manuals, FAQs, and policies
- ğŸ’¬ **Conversational Memory**: Maintains conversation context across sessions
- ğŸ” **Source Attribution**: Shows which documents were used to generate answers
- ğŸ› ï¸ **Multi-Tool Integration**: 
  - Order lookup and tracking
  - Support ticket creation
  - Address management
- ğŸ¨ **Modern UI**: Clean, responsive chat interface built with Next.js
- ğŸ“Š **Health Monitoring**: Built-in health check endpoints
- ğŸ”’ **Session Management**: Secure session handling with UUID-based identifiers

### Knowledge Base Coverage

- Product Manuals (Smart Bulbs, Cameras, Hubs, Door Locks)
- Troubleshooting Guides (Network, Connectivity, Pairing Issues)
- Policy Documents (Privacy, Returns, Shipping, Warranty)
- FAQ Sections (Account, Device, Orders, Payments)
- Advanced Settings Guides

---

## ğŸ› ï¸ Tech Stack

### Backend

- **Framework**: FastAPI 0.110.0
- **AI/ML**:
  - LangChain 0.3.7
  - Google Gemini 2.5 Flash
  - Sentence Transformers
- **Vector Database**: FAISS
- **Memory**: Redis 5.0.1
- **Server**: Uvicorn 0.30.1

### Frontend

- **Framework**: Next.js 16.0.6
- **Language**: TypeScript 5
- **UI**: React 19.2.0
- **Styling**: CSS Modules

### Data Processing

- **Embeddings**: Sentence Transformers
- **Text Splitting**: LangChain Text Splitters
- **Storage**: JSON files for orders, tickets, users

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Next.js UI    â”‚
â”‚   (Frontend)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP/REST
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI       â”‚
â”‚   (Backend)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
    â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RAG   â”‚ â”‚  Agent   â”‚
â”‚ System â”‚ â”‚ Executor â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
    â”‚          â”‚
    â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FAISS  â”‚ â”‚  Tools   â”‚
â”‚ Vector â”‚ â”‚ (Orders, â”‚
â”‚ Store  â”‚ â”‚ Tickets)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Redis      â”‚
â”‚  (Memory)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Prerequisites

Before you begin, ensure you have the following installed:

- **Python**: 3.8 or higher
- **Node.js**: 18.0 or higher
- **npm** or **yarn**: Latest version
- **Redis**: 5.0+ (optional, for conversation memory)
- **Google API Key**: For Gemini AI access

---

## ğŸš€ Installation

### 1. Clone the Repository

```bash
git clone <repository-url>
cd customer_support_ai
```

### 2. Backend Setup

```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Frontend Setup

```bash
cd frontend
npm install
```

---

## âš™ï¸ Configuration

### Backend Environment Variables

Create a `.env` file in the project root:

```env
# Required: Google Gemini API Key
GOOGLE_API_KEY=your_google_api_key_here
# OR
GEMINI_API_KEY=your_google_api_key_here

# Optional: Redis Configuration (for conversation memory)
REDIS_URL=redis://localhost:6379/0
RAG_MEMORY_MAX_HISTORY=10
RAG_MEMORY_TTL=604800
```

### Frontend Environment Variables

Create `frontend/.env.local` (optional):

```env
NEXT_PUBLIC_API_URL=http://localhost:8000
```

**Note**: If not set, the frontend defaults to `http://localhost:8000`

---

## ğŸƒ Running the Application

### Development Mode

#### Start Backend

```bash
# Activate virtual environment first
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

Or run directly:

```bash
python app/main.py
```

#### Start Frontend

```bash
cd frontend
npm run dev
```

### Production Mode

#### Build Frontend

```bash
cd frontend
npm run build
npm start
```

#### Run Backend

```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

### Access Points

- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs
- **Alternative Docs**: http://localhost:8000/redoc
- **Health Check**: http://localhost:8000/health

---

## ğŸ“¡ API Reference

### Base URL

```
http://localhost:8000
```

### Endpoints

#### Health Check

```http
GET /health
```

**Response:**
```json
{
  "status": "ok",
  "message": "Service is healthy",
  "api_key_configured": true
}
```

#### Ask Question (POST)

```http
POST /ask
Content-Type: application/json

{
  "question": "How do I pair my smart bulb?",
  "k": 5,
  "include_sources": true
}
```

**Response:**
```json
{
  "answer": "To pair your smart bulb...",
  "sources": [
    {
      "title": "Bulb Pairing Guide",
      "score": 0.95,
      "category": "product_manuals",
      "source_file": "nh_bulb_glow_rgb_manual.md",
      "section": "Pairing"
    }
  ]
}
```

#### Agent Ask (POST)

```http
POST /agent/ask
Content-Type: application/json

{
  "session_id": "user-123-session",
  "question": "My bulb won't connect to the hub",
  "k": 5,
  "force_rag": null
}
```

**Response:**
```json
{
  "session_id": "user-123-session",
  "message": "My bulb won't connect to the hub",
  "answer": "Here's how to troubleshoot...",
  "sources": [...],
  "tool_used": "rag"
}
```

#### Chat Message (POST)

```http
POST /chat/message
Content-Type: application/json

{
  "session_id": "conversation-456",
  "message": "What's your return policy?",
  "k": 5
}
```

### Interactive API Documentation

Visit `http://localhost:8000/docs` for interactive Swagger UI documentation where you can test all endpoints directly.

---

## ğŸ“ Project Structure

```
customer_support_ai/
â”œâ”€â”€ app/                          # Backend application
â”‚   â”œâ”€â”€ agent/                    # LangChain agent implementation
â”‚   â”‚   â””â”€â”€ support_agent.py      # Main agent with ReAct logic
â”‚   â”œâ”€â”€ api/                      # API routes
â”‚   â”‚   â”œâ”€â”€ routes.py             # API router
â”‚   â”‚   â””â”€â”€ ask.py                # Agent ask endpoint
â”‚   â”œâ”€â”€ chat/                     # Chat chain implementation
â”‚   â”‚   â””â”€â”€ chat_chain.py
â”‚   â”œâ”€â”€ memory/                   # Conversation memory
â”‚   â”‚   â””â”€â”€ memory.py             # Redis-based memory store
â”‚   â”œâ”€â”€ rag/                      # RAG system
â”‚   â”‚   â”œâ”€â”€ chunker.py            # Text chunking
â”‚   â”‚   â”œâ”€â”€ embedder.py           # Embedding generation
â”‚   â”‚   â”œâ”€â”€ loader.py             # Document loading
â”‚   â”‚   â”œâ”€â”€ query_engine.py       # Query processing
â”‚   â”‚   â”œâ”€â”€ rag_chain.py          # RAG chain implementation
â”‚   â”‚   â””â”€â”€ vector_store.py       # FAISS vector store
â”‚   â”œâ”€â”€ routes/                   # Additional routes
â”‚   â”‚   â””â”€â”€ chat_router.py        # Chat router
â”‚   â”œâ”€â”€ tools/                    # Agent tools
â”‚   â”‚   â”œâ”€â”€ order_tool.py         # Order lookup tool
â”‚   â”‚   â”œâ”€â”€ ticket_tool.py        # Ticket creation tool
â”‚   â”‚   â””â”€â”€ user_tool.py          # User management tool
â”‚   â”œâ”€â”€ utils/                    # Utilities
â”‚   â”‚   â””â”€â”€ logger.py             # Logging configuration
â”‚   â””â”€â”€ main.py                   # FastAPI application entry point
â”‚
â”œâ”€â”€ frontend/                     # Next.js frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/                  # Next.js app directory
â”‚   â”‚   â”‚   â”œâ”€â”€ layout.tsx        # Root layout
â”‚   â”‚   â”‚   â””â”€â”€ page.tsx          # Home page
â”‚   â”‚   â”œâ”€â”€ components/           # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInterface.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ MessageBubble.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ InputArea.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ TypingIndicator.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ SourceList.tsx
â”‚   â”‚   â”‚   â””â”€â”€ ToolIndicator.tsx
â”‚   â”‚   â”œâ”€â”€ lib/                  # Utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ api.ts            # API client
â”‚   â”‚   â”‚   â””â”€â”€ session.ts        # Session management
â”‚   â”‚   â””â”€â”€ types/                # TypeScript types
â”‚   â”‚       â””â”€â”€ api.ts
â”‚   â”œâ”€â”€ public/                   # Static assets
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ data/                         # Data files
â”‚   â”œâ”€â”€ knowledge_base/           # Knowledge base documents
â”‚   â”‚   â”œâ”€â”€ faqs/                 # FAQ documents
â”‚   â”‚   â”œâ”€â”€ policy_documents/     # Policy documents
â”‚   â”‚   â”œâ”€â”€ product_manuals/      # Product manuals
â”‚   â”‚   â””â”€â”€ troubleshooting_guides/ # Troubleshooting guides
â”‚   â”œâ”€â”€ embeddings.npy            # Pre-computed embeddings
â”‚   â”œâ”€â”€ faiss_index.bin           # FAISS vector index
â”‚   â”œâ”€â”€ metadata.jsonl            # Document metadata
â”‚   â”œâ”€â”€ orders.json               # Order data
â”‚   â”œâ”€â”€ tickets.json              # Ticket data
â”‚   â””â”€â”€ users.json                # User data
â”‚
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ .gitignore                    # Git ignore rules
â””â”€â”€ README.md                     # This file
```

---

## ğŸ” Environment Variables

### Backend

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `GOOGLE_API_KEY` | Yes* | - | Google Gemini API key |
| `GEMINI_API_KEY` | Yes* | - | Alternative API key variable |
| `REDIS_URL` | No | `redis://localhost:6379/0` | Redis connection URL |
| `RAG_MEMORY_MAX_HISTORY` | No | `10` | Max conversation history length |
| `RAG_MEMORY_TTL` | No | `604800` | Session TTL in seconds (7 days) |

*At least one API key is required

### Frontend

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `NEXT_PUBLIC_API_URL` | No | `http://localhost:8000` | Backend API URL |

---

## ğŸ§ª Testing

### Backend Testing

```bash
# Run health check
curl http://localhost:8000/health

# Test ask endpoint
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "How do I pair my bulb?", "include_sources": true}'
```

### Frontend Testing

The frontend can be tested by:
1. Starting both backend and frontend servers
2. Opening http://localhost:3000
3. Sending test messages through the chat interface

### Using Postman

See the API documentation at `/docs` for detailed endpoint specifications. You can also import the OpenAPI schema from `/openapi.json`.

---

## ğŸš¢ Deployment

### Backend Deployment

1. Set environment variables on your hosting platform
2. Install dependencies: `pip install -r requirements.txt`
3. Run with production server:
   ```bash
   uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
   ```

### Frontend Deployment

1. Build the application:
   ```bash
   cd frontend
   npm run build
   ```

2. Set `NEXT_PUBLIC_API_URL` to your production backend URL

3. Deploy to Vercel, Netlify, or your preferred platform

### Production Considerations

- **CORS**: Update `allow_origins` in `app/main.py` to restrict allowed origins
- **API Keys**: Use secure environment variable management
- **Redis**: Set up production Redis instance for conversation memory
- **Monitoring**: Add logging and monitoring solutions
- **Rate Limiting**: Implement rate limiting for API endpoints
- **HTTPS**: Use HTTPS in production

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Guidelines

- Follow PEP 8 for Python code
- Use TypeScript for frontend code
- Write clear commit messages
- Add tests for new features
- Update documentation as needed

---

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ“ Support

For issues, questions, or contributions, please open an issue on the GitHub repository.

---

## ğŸ™ Acknowledgments

- [LangChain](https://www.langchain.com/) for the agent framework
- [FastAPI](https://fastapi.tiangolo.com/) for the web framework
- [Next.js](https://nextjs.org/) for the frontend framework
- [Google Gemini](https://ai.google.dev/) for the AI model

---

<div align="center">

**Built with â¤ï¸ for intelligent customer support**

</div>
